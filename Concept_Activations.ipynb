{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c9344-fb1b-4e13-8312-ba6f4c9af6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818feb57-2691-44b1-83e8-597281dba623",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobertaTokenizerFast, RobertaModel\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CBL, RobertaCBL\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mCFG\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# visualize_activations.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizerFast, RobertaModel\n",
    "from modules import CBL, RobertaCBL\n",
    "import config as CFG\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45016ba6-4dee-423f-a0c4-65c124074f1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobertaTokenizerFast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load tokenizer and models\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RobertaTokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m cbl \u001b[38;5;241m=\u001b[39m CBL(\u001b[38;5;28mlen\u001b[39m(CFG\u001b[38;5;241m.\u001b[39mconcept_set[args\u001b[38;5;241m.\u001b[39mdataset]))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m cbl\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcbl_path mpnet_acs/SetFit_sst2/roberta_cbm/cbl_acc_epoch_10.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RobertaTokenizerFast' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokenizer and models\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "cbl = CBL(len(CFG.concept_set[args.dataset])).to(device)\n",
    "cbl.load_state_dict(torch.load('cbl_path mpnet_acs/SetFit_sst2/roberta_cbm/cbl_acc_epoch_10.pt'))\n",
    "cbl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb4615-61b9-4aef-8486-d1a0f1a516f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final predictor\n",
    "final_predictor = torch.load('path_to_final_predictor.pt')\n",
    "\n",
    "# Load concept list\n",
    "concepts = CFG.concept_set[args.dataset]\n",
    "\n",
    "# Function to get activations\n",
    "def get_activations(input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        # Get embeddings from language model\n",
    "        outputs = RobertaModel.from_pretrained('roberta-base').to(device)(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        # Get concept activations\n",
    "        concept_activations = cbl(cls_embedding)\n",
    "        concept_activations = F.relu(concept_activations)\n",
    "\n",
    "        # Get prediction\n",
    "        logits = final_predictor(concept_activations)\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    activations = concept_activations.cpu().numpy().flatten()\n",
    "    return activations, prediction\n",
    "\n",
    "# Visualization\n",
    "def visualize_activations(activations, concepts):\n",
    "    # Sort concepts by activation\n",
    "    sorted_indices = np.argsort(-activations)\n",
    "    sorted_concepts = [concepts[i] for i in sorted_indices]\n",
    "    sorted_activations = activations[sorted_indices]\n",
    "\n",
    "    # Plot bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(sorted_concepts[:10], sorted_activations[:10])  # Top 10 concepts\n",
    "    plt.xlabel('Activation')\n",
    "    plt.title('Top Activated Concepts')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "input_text = \"The restaurant had great food but the service was terrible.\"\n",
    "activations, prediction = get_activations(input_text)\n",
    "visualize_activations(activations, concepts)\n",
    "print(\"Prediction:\", \"Positive\" if prediction == 1 else \"Negative\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
